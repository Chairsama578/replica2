{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtaA1MmKqZJiTBX1ZEtte4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chairsama578/replica2/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1i6zYCPplKG"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Install dependencies\n",
        "!pip install kagglehub tensorflow keras opencv-python joblib matplotlib seaborn scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Import libraries\n",
        "import os\n",
        "import shutil\n",
        "import kagglehub\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2, EfficientNetB0\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import joblib\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-owUucSOpoDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Download and map dataset to 5 classes\n",
        "DATASET_SLUG = \"sumn2u/garbage-classification-v2\"\n",
        "path = kagglehub.dataset_download(DATASET_SLUG)\n",
        "print(\"Dataset downloaded to:\", path)\n",
        "\n",
        "# Original classes (based on dataset)\n",
        "original_classes = ['Metal', 'Glass', 'Biological', 'Paper', 'Battery', 'Trash', 'Cardboard', 'Shoes', 'Clothes', 'Plastic']\n",
        "\n",
        "# Mapping to 5 classes as per report\n",
        "class_mapping = {\n",
        "    'Paper': 'paper',\n",
        "    'Cardboard': 'paper',\n",
        "    'Plastic': 'plastic',\n",
        "    'Metal': 'metal',\n",
        "    'Glass': 'glass',\n",
        "    'Biological': 'organic'\n",
        "    # Exclude: Battery, Trash, Shoes, Clothes\n",
        "}\n",
        "\n",
        "# Create images_raw/ with 5 subfolders\n",
        "images_raw = 'images_raw'\n",
        "os.makedirs(images_raw, exist_ok=True)\n",
        "class_counts = {c: 0 for c in set(class_mapping.values())}\n",
        "\n",
        "for orig_class in original_classes:\n",
        "    src_dir = os.path.join(path, orig_class)  # Assume structure: root/class/image.jpg\n",
        "    if os.path.exists(src_dir) and orig_class in class_mapping:\n",
        "        target_class = class_mapping[orig_class]\n",
        "        target_dir = os.path.join(images_raw, target_class)\n",
        "        os.makedirs(target_dir, exist_ok=True)\n",
        "        for img in os.listdir(src_dir):\n",
        "            if img.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "                shutil.copy(os.path.join(src_dir, img), os.path.join(target_dir, img))\n",
        "                class_counts[target_class] += 1\n",
        "\n",
        "print(\"Mapped class counts (approximate as per report):\", class_counts)\n",
        "# Expected: paper ~4100+ (Paper+Cardboard), plastic ~1439, metal ~1077, glass ~3199, organic ~997\n",
        "\n",
        "# Plot distribution\n",
        "plt.bar(class_counts.keys(), class_counts.values())\n",
        "plt.title(\"Phân bố dataset 5 lớp\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VPIMIkA2pvfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Data augmentation and generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2  # 80% train, 20% val\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    images_raw,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    images_raw,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Save class indices (labels)\n",
        "os.makedirs('models', exist_ok=True)\n",
        "joblib.dump(train_generator.class_indices, 'models/labels.pkl')"
      ],
      "metadata": {
        "id": "XJvBAodxpwdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Build and train primary model (MobileNetV2)\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Freeze base\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.5),\n",
        "    Dense(5, activation='softmax')  # 5 classes\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=5, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(factor=0.2, patience=3)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=50,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Fine-tuning: Unfreeze base and retrain with low LR\n",
        "base_model.trainable = True\n",
        "model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "fine_history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=20,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Save model\n",
        "model.save('models/waste_model.h5')\n",
        "\n",
        "# Plot training curves\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'] + fine_history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'] + fine_history.history['val_accuracy'], label='Val Acc')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'] + fine_history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'] + fine_history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G6071tdKpzKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Evaluation (confusion matrix, classification report)\n",
        "# Get predictions on validation set\n",
        "val_steps = validation_generator.samples // validation_generator.batch_size\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for _ in range(val_steps):\n",
        "    x, y = next(validation_generator)\n",
        "    pred = model.predict(x)\n",
        "    y_true.extend(np.argmax(y, axis=1))\n",
        "    y_pred.extend(np.argmax(pred, axis=1))\n",
        "\n",
        "# Report and confusion matrix\n",
        "print(classification_report(y_true, y_pred, target_names=list(train_generator.class_indices.keys())))\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=list(train_generator.class_indices.keys()), yticklabels=list(train_generator.class_indices.keys()))\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qXWe0Fq4p38T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Comparison model (EfficientNetB0) - Optional, run if needed\n",
        "base_eff = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_eff.trainable = False\n",
        "\n",
        "model_eff = Sequential([\n",
        "    base_eff,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.5),\n",
        "    Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "model_eff.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_eff = model_eff.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=50,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Compare accuracies (simple print)\n",
        "print(\"MobileNetV2 Val Acc:\", max(history.history['val_accuracy'] + fine_history.history['val_accuracy']))\n",
        "print(\"EfficientNetB0 Val Acc:\", max(history_eff.history['val_accuracy']))"
      ],
      "metadata": {
        "id": "p6cAa71Hp6QI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}